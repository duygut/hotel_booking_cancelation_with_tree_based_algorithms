{"cells":[{"metadata":{},"cell_type":"markdown","source":"## **Summary**\n\nEvery year, more than 140 million bookings made on the internet and many hotel bookings made through top-visited travel websites like Booking.com, Expedia.com, Hotels.com, etc. According to Google data, hotels are booked in advance of 12 weeks. \n\nThis dataset contains 31 features about booking information such as Average Daily Rate, Arrival Time, Room Type, Special Request, etc. between 2015 and 2017 years.\n\nIn this kernel, I would like to show some booking information details with exploratory data analysis, some feature engineering, reviewing correlations between features, hyperparameter tunning and visualizing most important features and their interesting distribution properties. \nAs a result of all these analyses, I aim to find best model to predict hotel booking cancellations with tree-based algorithms based on rest of the features found in the dataset. \nThe goal of predictive analysis is to avoid overfitting and find the model that has the highest accuracy. "},{"metadata":{},"cell_type":"markdown","source":"## **INTRODUCTION**"},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom matplotlib import pyplot\nimport seaborn as sns\n\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split\n\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.model_selection import GridSearchCV\n\nimport xgboost as xgb\nfrom xgboost import XGBClassifier\n\nfrom sklearn.inspection import permutation_importance\n\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.ensemble import ExtraTreesClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom sklearn.ensemble import VotingClassifier\n\nfrom sklearn.metrics import accuracy_score \nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import confusion_matrix","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 1. Data Information"},{"metadata":{"trusted":true},"cell_type":"code","source":"hotel_data = pd.read_csv('../input/hotel-booking-demand/hotel_bookings.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"hotel_data.head(10)","execution_count":null,"outputs":[]},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"hotel_data.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 2. Exploratory Data Analysis and Feature Engineering"},{"metadata":{},"cell_type":"markdown","source":"In this part, I would like to visualize some features and show statistical relationship with target variable. This analysis will help to get overall view and deep familiarity of the data, detect extreme values and identify obvious errors. "},{"metadata":{},"cell_type":"markdown","source":"First graph is about exploring `hotel` feature which denotes type of the hotels. According to the below graph, approximately 34% of the data was booked for resort hotel and the rest of was booked for City Hotel. "},{"metadata":{"trusted":true},"cell_type":"code","source":"# Hotel Types\nplt.figure(figsize=(10,10))\nsns.countplot(x='hotel', data = hotel_data, palette='gist_earth')\nplt.title('Hotel Types', weight='bold')\nplt.xlabel('Hotel', fontsize=12)\nplt.ylabel('Count', fontsize=12)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now, let's dive into the target value of data. The numbers are similar with hotel features. While 37% of booking canceled, 63% of booking is not canceled. These numbers also show that there is no balanced problem on the target value.  "},{"metadata":{"trusted":true},"cell_type":"code","source":"# Is canceled or Not\nplt.figure(figsize=(10,10))\nsns.countplot(y='is_canceled', data= hotel_data, palette='gist_stern', orient = 'v')\nplt.title('Canceled Situation', weight='bold')\nplt.xlabel('Count', fontsize=12)\nplt.ylabel('Canceled or Not Canceled', fontsize=12)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Below graph shows the relationship of `arrival_date_year` to `lead_time` with booking cancellation status. The graph created by violin plot. Violin plot is a hybrid of box plot and density plot. It shows the distribution of the data. \n\nThree violin plots are correponding to three different years. For canceled booking, means and interquartile ranges are similar in all years. But the shapes of the distributions are quite different from each other. On the other hand distribution of not-canceled booking are almost the same. \nFor all years and every booking situation, the small number of large lead time values are pulling the mean up. It shows that the mean is higher than the median. "},{"metadata":{"trusted":true},"cell_type":"code","source":"# Yearly hotel types\nplt.figure(figsize=(10,10))\nsns.violinplot(x='arrival_date_year', y ='lead_time', hue=\"is_canceled\", data=hotel_data, palette=\"Set3\", bw=.2,\n               cut=2, linewidth=2, iner= 'box', split = True)\nsns.despine(left=True)\nplt.title('Arrival Year vs Lead Time vs Canceled Situation', weight='bold')\nplt.xlabel('Year', fontsize=12)\nplt.ylabel('Lead Time', fontsize=12)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Another exploration is made for the `arrival_date_month` feature. First month names converted to the numbers. It will help easier analysis. "},{"metadata":{"trusted":true},"cell_type":"code","source":"#Arrival Time Exploration\n\nhotel_data['arrival_date_month'].replace({'January' : '1',\n        'February' : '2',\n        'March' : '3',\n        'April' : '4',\n        'May' : '5',\n        'June' : '6',\n        'July' : '7',\n        'August' : '8',\n        'September' : '9', \n        'October' : '10',\n        'November' : '11',\n        'December' : '12'}, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(15,10))\nsns.countplot(x='arrival_date_month', data = hotel_data,\n              order=pd.value_counts(hotel_data['arrival_date_month']).index, palette='YlOrBr_r')\nplt.title('Arrival Month', weight='bold')\nplt.xlabel('Month', fontsize=12)\nplt.ylabel('Count', fontsize=12)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The above graph is showing the number of bookings for each month. According to that, August is the busiest month and January is the most unoccupied month. It is half as busy as August."},{"metadata":{},"cell_type":"markdown","source":"Another important features which are related to time are `stays_in_week_nights` and `stays_in_weekend_night` features. The below table shows the relationship between these two features. According to that, there is some missing data. 715 values are inputted zero both weekend and weeknights. However, this missing data is small enough to neglect. "},{"metadata":{"trusted":true},"cell_type":"code","source":"#Stay in weekend vs Stay in week nights\npd.crosstab(index = hotel_data['stays_in_week_nights'],columns=hotel_data['stays_in_weekend_nights'], margins=True, margins_name = 'Total').iloc[:10]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The above table brings an idea about creating a new feature. Which is indicated `just_stay_weekend`, `just_stay_weekday` and `stay_both_weekday_and_weekday`. These 715 values which are not assigned any feature, indicated as undefined_data."},{"metadata":{"trusted":true},"cell_type":"code","source":"# ## Weekday vs Weekend \n\n# pd.options.mode.chained_assignment = None\n# hotel_data['weekend_or_weekday'] = 0\n# for i in range(0, len(hotel_data)):\n#     if hotel_data['stays_in_weekend_nights'].iloc[i] > 0 and hotel_data['stays_in_week_nights'].iloc[i] == 0:\n#         hotel_data['weekend_or_weekday'].iloc[i] = 'stay_just_weekend'\n#     if hotel_data['stays_in_week_nights'].iloc[i] > 0 and hotel_data['stays_in_weekend_nights'].iloc[i] == 0:\n#         hotel_data['weekend_or_weekday'].iloc[i] = 'stay_just_weekday'\n#     if hotel_data['stays_in_week_nights'].iloc[i] > 0 and hotel_data['stays_in_weekend_nights'].iloc[i] > 0:\n#         hotel_data['weekend_or_weekday'].iloc[i] = 'stay_both_weekday_and_weekend'\n#     if hotel_data['stays_in_week_nights'].iloc[i] == 0 and hotel_data['stays_in_weekend_nights'].iloc[i] == 0:\n#         hotel_data['weekend_or_weekday'].iloc[i] = 'undefined_data'\n# # hotel_data['weekend_or_weekday'] = hotel_data['weekend_or_weekday'].astype(str)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## Weekday vs Weekend \n\npd.options.mode.chained_assignment = None\ndef week_function(feature1, feature2, data_source):\n    data_source['weekend_or_weekday'] = 0\n    for i in range(0, len(data_source)):\n        if feature2.iloc[i] == 0 and feature1.iloc[i] > 0:\n            hotel_data['weekend_or_weekday'].iloc[i] = 'stay_just_weekend'\n        if feature2.iloc[i] > 0 and feature1.iloc[i] == 0:\n            hotel_data['weekend_or_weekday'].iloc[i] = 'stay_just_weekday'\n        if feature2.iloc[i] > 0 and feature1.iloc[i] > 0:\n            hotel_data['weekend_or_weekday'].iloc[i] = 'stay_both_weekday_and_weekend'\n        if feature2.iloc[i] == 0 and feature1.iloc[i] == 0:\n            hotel_data['weekend_or_weekday'].iloc[i] = 'undefined_data'\n        \n# value1 = hotel_data['stays_in_weekend_nights']\n# value2 = hotel_data['stays_in_week_nights']\nweek_function(hotel_data['stays_in_weekend_nights'],hotel_data['stays_in_week_nights'], hotel_data)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Next graph is about `weekend_or_weekday` feature's relationship with `arrival_date_month`. Below bar graph shows that most bookings were made to stay only for weekdays or both weekdays and weekends. On the other, numbers of staying just the weekend category are quite low compared to other categories. "},{"metadata":{"trusted":true},"cell_type":"code","source":"hotel_data['arrival_date_month']= hotel_data['arrival_date_month'].astype('int64')\ngroup_data = hotel_data.groupby([ 'arrival_date_month','weekend_or_weekday']).size().unstack(fill_value=0)\ngroup_data.sort_values('arrival_date_month', ascending = True).plot(kind='bar',stacked=True, cmap='Set2',figsize=(15,10))\nplt.title('Arrival Month vs Staying Weekend or Weekday', weight='bold')\nplt.xlabel('Arrival Month', fontsize=12)\nplt.xticks(rotation=360)\nplt.ylabel('Count', fontsize=12)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Another feature engineering is made for `children` and `babies` features. Since, there is no obvious difference, these features gathered under the one feature which name is `all_children`."},{"metadata":{"trusted":true},"cell_type":"code","source":"#Merge children and baby\nhotel_data['all_children'] = hotel_data['children'] + hotel_data['babies']\npd.crosstab(hotel_data['adults'], hotel_data['all_children'], margins=True, margins_name = 'Total').iloc[:10]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Below the donut pie graph shows the meal categories. There is a big difference in the `Bed&Breakfast` category and the others. Almost 80% of bookings reserved for `Bed&Breakfast`. "},{"metadata":{"trusted":true},"cell_type":"code","source":"## Meal\nmeal_labels= ['BB','HB', 'SC', 'Undefined', 'FB']\nsize = hotel_data['meal'].value_counts()\nplt.figure(figsize=(10,10))\ncmap =plt.get_cmap(\"Pastel2\")\ncolors = cmap(np.arange(3)*4)\nmy_circle=plt.Circle( (0,0), 0.7, color='white')\nplt.pie(size, labels=meal_labels, colors=colors, wedgeprops = { 'linewidth' : 5, 'edgecolor' : 'white' })\np=plt.gcf()\np.gca().add_artist(my_circle)\nplt.title('Meal Types', weight='bold')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The below table shows frequency details about meal types according to the hotel types. Following the results, 67% of `Bed&Breakfast` booking made for `City Hotel` and almost every `Full Board` bookings made in the `Resort Hotel`."},{"metadata":{"trusted":true},"cell_type":"code","source":"group_meal_data = hotel_data.groupby(['hotel','meal']).size().unstack(fill_value=0).transform(lambda x: x/x.sum())\ngroup_meal_data.applymap('{:.2f}'.format)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The below graph gives information about the location which bookings made in. According to that, there is an apparent difference in booking location between Portugal and the others. Approx. 40% of all bookings made in the same location: Portugal. "},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(10,10))\nsns.countplot(x='country', data=hotel_data, \n              order=pd.value_counts(hotel_data['country']).iloc[:10].index, palette=\"brg\")\nplt.title('Top 10 Country of Origin', weight='bold')\nplt.xlabel('Country', fontsize=12)\nplt.ylabel('Count', fontsize=12)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The statistics show that online hotel and airline reservations are increased in recent years. Most people complete their reservation via their smartphones. The below graphs is summarise these statistics. More than 45% of bookings are made via `Online Travel Agents` and around 20% of bookings made via `Offline Travel Agents`. Less than 20% of bookings made directly without any agents. "},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(10,10))\nsns.countplot(hotel_data['market_segment'], palette='spring_r', \n              order=pd.value_counts(hotel_data['market_segment']).index)\nplt.title('Market Segment Types', weight='bold')\nplt.xlabel('Market Segment', fontsize=12)\nplt.ylabel('Count', fontsize=12)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Below crosstable shows if there is any difference between assigned and reserved room types or not. The results are shown as a percentage. Average 84% of bookings keep their reserved room and the rest of the' rooms have been changed. Every row represents the reserved type and distribution over the columns shows what was the assigned room despite of reserved type."},{"metadata":{"trusted":true},"cell_type":"code","source":"## Reserved vs Assigned Room\npd.crosstab(index = hotel_data['reserved_room_type'], \n            columns = hotel_data['assigned_room_type'],normalize='index').round(2)*100","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Another exploratory analysis made for diving deep into the relationship between ADR and arrival month and booking cancellation status. As explained in the previous graph of `arrival month`, August is the most intense month of bookings. Besides the highest `Arrival Daily Rate` has ben occurred in that month too. Except for rush months like August, July, and September, canceled bookings have higher `ADR` than not canceled bookings. Maybe this highest rate could be one of the reasons for canceled bookings."},{"metadata":{"trusted":true},"cell_type":"code","source":"hotel_data['adr'] = hotel_data['adr'].astype(float)\nplt.figure(figsize=(15,10))\nsns.barplot(x='arrival_date_month', y='adr', hue='is_canceled', dodge=True, palette= 'PuBu_r', data=hotel_data)\nplt.title('Arrival Month vs ADR vs Booking Cancellation Status', weight='bold')\nplt.xlabel('Arrival Month', fontsize=12)\nplt.ylabel('ADR', fontsize=12)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The below graph is about `Total Special Request` numbers. Around 55% of bookings do not have any special requests. "},{"metadata":{"trusted":true},"cell_type":"code","source":"# Total of special requests\nplt.figure(figsize=(10,10))\nsns.countplot(x='total_of_special_requests', data=hotel_data, palette = 'ocean_r')\nplt.title('Total Special Request', weight='bold')\nplt.xlabel('Number of Special Request', fontsize=12)\nplt.ylabel('Count', fontsize=12)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The last graph is about the relationship between special requests and cancellation booking status. Nearly half bookings without any special requests have been canceled and another half of them have not been canceled. "},{"metadata":{"trusted":true},"cell_type":"code","source":"group_adr_request = hotel_data.groupby([ 'total_of_special_requests', 'is_canceled']).size().unstack(fill_value=0)\ngroup_adr_request.plot(kind='bar', stacked=True, cmap='vlag', figsize=(10,10))\nplt.title('Total Special Request vs Booking Cancellation Status', weight='bold')\nplt.xlabel('Number of Special Request', fontsize=12)\nplt.xticks(rotation=360)\nplt.ylabel('Count', fontsize=12)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 3. Dealing with Missing Data and Correlation Matrix"},{"metadata":{},"cell_type":"markdown","source":"In this part, first of all, any missing data will be checked.\nThe below code shows missing data for every feature. Such that, the `company` feature's 94% is missing. Because of that, this feature will be eliminated. On the other hand, the `children` and `all_children` features have only 4 missing data. This missing data will replace with zero. Another missing data has occurred in `country` and `agent` features. \nSince missing data of `country` is less than 1%, these data will replace with most frequent value. However, the `agent` missing features are more than the country. For this feature, missing data will be imputed as `0`. "},{"metadata":{"trusted":true},"cell_type":"code","source":"## Missing Data\nhotel_data.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"hotel_data['children'] =  hotel_data['children'].fillna(0)\nhotel_data['all_children'] =  hotel_data['all_children'].fillna(0)\nhotel_data['country'] = hotel_data['country'].fillna(hotel_data['country'].mode().index[0])\nhotel_data['agent']= hotel_data['agent'].fillna('0')\nhotel_data=hotel_data.drop(['company'], axis =1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"hotel_data['agent']= hotel_data['agent'].astype(int)\nhotel_data['country']= hotel_data['country'].astype(str)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Another part is analyzing categorical features. Categorical labels converted into numerical form. This will help to be more understandable and implementable into machine learning algorithms. Some features are not ordinal such as `country`. In that case, *One-Hot Encoding* could be chosen. Due to the high number of categories, this method could incur higher computational cost. To help reducing that, Label Encoding method will be used."},{"metadata":{"trusted":true},"cell_type":"code","source":"labelencoder = LabelEncoder()\nhotel_data['hotel'] = labelencoder.fit_transform(hotel_data['hotel'])\nhotel_data['arrival_date_month'] = labelencoder.fit_transform(hotel_data['arrival_date_month'])\nhotel_data['meal'] = labelencoder.fit_transform(hotel_data['meal'])\nhotel_data['country'] = labelencoder.fit_transform(hotel_data['country'])\nhotel_data['market_segment']= labelencoder.fit_transform(hotel_data['market_segment'])\nhotel_data['distribution_channel']=labelencoder.fit_transform(hotel_data['distribution_channel'])\nhotel_data['is_repeated_guest'] = labelencoder.fit_transform(hotel_data['is_repeated_guest'])\nhotel_data['reserved_room_type'] = labelencoder.fit_transform(hotel_data['reserved_room_type'])\nhotel_data['assigned_room_type'] = labelencoder.fit_transform(hotel_data['assigned_room_type'])\nhotel_data['deposit_type'] = labelencoder.fit_transform(hotel_data['deposit_type'])\nhotel_data['agent'] = labelencoder.fit_transform(hotel_data['agent'])\nhotel_data['customer_type'] = labelencoder.fit_transform(hotel_data['customer_type'])\nhotel_data['reservation_status'] = labelencoder.fit_transform(hotel_data['reservation_status'])\nhotel_data['weekend_or_weekday'] = labelencoder.fit_transform(hotel_data['weekend_or_weekday'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"After encoding the categorical data, two data frames will be created. One data frame has only categorical data and another has numerical data. These two different data frames will be used to create a correlation matrix. *Spearman* method will be used for categorical data correlation matrix and *Pearson* method will be used for numerical one. "},{"metadata":{"trusted":true},"cell_type":"code","source":"hotel_data_categorical = hotel_data[['hotel','is_canceled','arrival_date_month','meal',\n                                     'country','market_segment','distribution_channel', \n                                     'is_repeated_guest', 'reserved_room_type',\n                                     'assigned_room_type','deposit_type','agent',\n                                     'customer_type','reservation_status', \n                                     'weekend_or_weekday']]\nhotel_data_categorical.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"hotel_data_numerical= hotel_data.drop(['hotel','is_canceled', 'arrival_date_month','meal',\n                                       'country','market_segment','distribution_channel', \n                                       'is_repeated_guest', 'reserved_room_type', \n                                       'assigned_room_type','deposit_type','agent', \n                                       'customer_type','reservation_status',\n                                       'weekend_or_weekday'], axis = 1)\nhotel_data_numerical.info()","execution_count":null,"outputs":[]},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(15,15))\ncorr_categorical=hotel_data_categorical.corr(method='spearman')\nmask_categorical = np.triu(np.ones_like(corr_categorical, dtype=np.bool))\nsns.heatmap(corr_categorical, annot=True, fmt=\".2f\", cmap='BrBG', vmin=-1, vmax=1, center= 0,\n            square=True, linewidths=2, cbar_kws={\"shrink\": .5}).set(ylim=(15, 0))\nplt.title(\"Correlation Matrix Spearman Method- Categorical Data \",size=15, weight='bold')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(15,15))\ncorr_numerical=hotel_data_numerical.corr(method='spearman')\nmask_numerical = np.triu(np.ones_like(corr_numerical, dtype=np.bool))\nsns.heatmap(corr_numerical, annot=True, fmt=\".2f\", cmap='RdBu', mask= mask_numerical, vmin=-1, vmax=1, center= 0,\n            square=True, linewidths=2, cbar_kws={\"shrink\": .5}).set(ylim=(17, 0))\nplt.title(\"Correlation Matrix Pearson Method- Numerical Data \",size=15, weight='bold')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Find highly correlated features\ncorr_mask_categorical = corr_categorical.mask(mask_categorical)\ncorr_values_categorical = [c for c in corr_mask_categorical.columns if any (corr_mask_categorical[c] > 0.90)]\ncorr_mask_numerical = corr_numerical.mask(mask_numerical)\ncorr_values_numerical = [c for c in corr_mask_numerical.columns if any (corr_mask_numerical[c] > 0.90)]\nprint(corr_values_categorical, corr_values_numerical)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The above correlation matrix shows positive or negative relationships between them. In those two heatmaps, the `reservation_ status` feature is drawn more attention because of its negative correlation with the `is_canceled` feature. The below table shows the relationship with details. This high correlation can cause a wrong prediction or overfitting. Prevent this situation, `reservation_status` feature will be eliminated. \n\nOn the other hand, there is another high relationship between the `children` and the `all_children` features, since the `all_children` feature is constituted with the `children` and the `babies` features. Therefore the `children` feature will be eliminated too.\n\nLast feature is `reservation_status_date`. Since this feature includes date type data and it could not convert another type, this feature will be eliminated. "},{"metadata":{"trusted":true},"cell_type":"code","source":"# Reservation Status\npd.crosstab(columns = hotel_data['reservation_status'], index = hotel_data['is_canceled'],\n           margins=True, margins_name = 'Total')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"hotel_data = hotel_data.drop(['reservation_status', 'children', 'reservation_status_date'], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Copying data \nhotel_data_model = hotel_data","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 4. Hyperparameter Tunning and Feature Importance"},{"metadata":{},"cell_type":"markdown","source":"In this part, optimum hyperparameters for several tree-based machine learning algorithms will be searched with the help of the `Grid Search Algorithm`. Hyperparameter tuning will help to make a prediction in the training part more accurately. Therefore, hyperparameters tunning will be fixed before the training process. \n\nAnother important work is constituted Permutation Feature Importance graph with the `Extreme Gradient Boosting` algorithm. This technique calculates feature importance and performance metric be chosen as the basis of the accuracy score. This graph will help to understand features' contributed to prediction, provide insight into the dataset, and will help to find deemed non-important features if any. "},{"metadata":{"trusted":true},"cell_type":"code","source":"hotel_data_tunning = hotel_data\ny = hotel_data_tunning.iloc[:,1]\nX = pd.concat([hotel_data_tunning.iloc[:,0],hotel_data_tunning.iloc[:,2:30]], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## XGBoost\n# model = XGBClassifier()\n# parameters = {\n# 'n_estimators' : [100,250,500],\n# 'learning_rate' : [0.01, 0.1],\n# 'subsample' :[0.5, 1.0],\n# 'max_depth' : [3,5,7],\n# 'criterion' : ['giny','entropy'],\n# 'objective':['binary:logistic'],\n# }\n\n# grid_search = GridSearchCV(estimator=model, param_grid=parameters,\n#                           cv=5, scoring='f1', verbose=True, n_jobs=-1)\n# grid_search.fit(X, y)\n# print(grid_search.best_score_)\n# print(grid_search.best_params_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# model_rfc_gs = RandomForestClassifier()\n# parameters_rfc = {\n# 'n_estimators' : [100,200,500],\n# 'min_samples_split' : [2,4,6,8],\n# 'min_samples_leaf': [1,2,4,6]\n# }\n\n# grid_search_rfc = GridSearchCV(estimator=model_rfc_gs, param_grid=parameters_rfc,\n#                           cv=5, scoring='f1', verbose=True, n_jobs=-1)\n# grid_search_rfc.fit(X, y)\n# grid_search_rfc.best_params_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# model_etc_gs = ExtraTreesClassifier()\n# parameters_etc = {\n# 'n_estimators' : [100,250,500],\n# 'min_samples_split' : [2,4,6,8],\n# 'min_samples_leaf': [1,3,5,7]\n# }\n\n# grid_search_etc = GridSearchCV(estimator=model_etc_gs, param_grid=parameters_etc,\n#                           cv=5, scoring='f1', verbose=True, n_jobs=-1)\n# grid_search_etc.fit(X, y)\n# grid_search_etc.best_params_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# model_dtc_gs = DecisionTreeClassifier()\n# parameters_dtc = {\n# 'criterion' : ['gini', 'entropy'],\n# 'min_samples_split' : [2,4,6,8],\n# 'min_samples_leaf': [1,2,3,4,5],\n# 'max_features' : ['auto', 'sqrt']\n# }\n\n# grid_search_dtc = GridSearchCV(estimator=model_dtc_gs, param_grid=parameters_dtc,\n#                           cv=5, scoring='f1', verbose=True, n_jobs =-1)\n# grid_search_dtc.fit(X, y)\n# grid_search_dtc.best_params_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"params = {\n    'criterion': 'giny', \n    'learning_rate': 0.01, \n    'max_depth': 5,\n    'n_estimators': 100, \n    'objective': 'binary:logistic', \n}\nmodel = XGBClassifier(parameters=params)\n# fit the model\nmodel.fit(X, y)\n# perform permutation importance\nresult = permutation_importance(model, X, y, scoring='accuracy', n_repeats = 5, n_jobs=-1)\nsorted_idx = result.importances_mean.argsort()","execution_count":null,"outputs":[]},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"for i,v in enumerate(sorted_idx):\n    print('Feature: %0d, Score: %.5f' % (i,v))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(figsize=(20,15))\n\nax.boxplot(result.importances[sorted_idx].T,\n           vert=False, labels=X.columns[sorted_idx])\nax.set_title(\"Permutation Importance\")\nfig.tight_layout()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The above graph shows the feature importance of the features. according to that, 1 out of 29 features are not being important to prediction which is `babies`. It will eliminated."},{"metadata":{"trusted":true},"cell_type":"code","source":"hotel_data_model = hotel_data_model.drop(['babies'], axis=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 5. Model Building"},{"metadata":{},"cell_type":"markdown","source":"In this part, some tree-based algorithms have been used for model building. These are *Decision Tree*, *Random Forest*, *Extra Trees Classifier*, and *Extreme Gradient Boosting*. *Random Forest* and *Extra Tree Classification* algorithms have been chosen as bagging algorithms, `XGBoost` has been chosen as one of the boosting algorithms. *Decision Tree* algorithm has been chosen as one tree algorithm. \n\nBefore model building, data will be split to train and test respectively 70% and 30% ratio. \n`X_train` and `X_test` data will be standardized with the *Standard Scaler* technique. After that, the *Stratified K-Fold Cross Validation* method will be used for resampling. Cross-validation is an important implementation to avoid overfitting. *Stratified K-Fold Cross Validation* method provides train/test indices to split data into train/test sets.\nModel parameters have been defined in the previous part. "},{"metadata":{"trusted":true},"cell_type":"code","source":"y_model = hotel_data_model.iloc[:,1]\nX_model = pd.concat([hotel_data_tunning.iloc[:,0],hotel_data_tunning.iloc[:,2:30]], axis=1)\ny_model.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(X_model, y_model, test_size=0.3, random_state=42, stratify = y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"standardScalerX = StandardScaler()\nX_train = standardScalerX.fit_transform(X_train)\nX_test = standardScalerX.fit_transform(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Stratified K-Fold Cross Validation Method\n\nkfold_cv=StratifiedKFold(n_splits=5, random_state=42, shuffle=True)\n\nfor train_index, test_index in kfold_cv.split(X_model,y_model):\n    X_train, X_test = X_model.iloc[train_index], X_model.iloc[test_index]\n    y_train, y_test = y_model.iloc[train_index], y_model.iloc[test_index]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Decision Tree \n\ndtc_model = DecisionTreeClassifier(criterion= 'gini', min_samples_split=8,\n                                  min_samples_leaf = 4, max_features = 'auto')\n# fit the model\ndtc_model.fit(X_train, y_train)\n\n#Predict Model\npredict_dtc = dtc_model.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Random Forest\nrf_model = RandomForestClassifier(min_samples_leaf = 6, min_samples_split=6,\n                                  n_estimators = 100)\n\n# fit the model\nestimator= rf_model.fit(X_train, y_train)\n#Predict Model\npredict_rf = rf_model.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Extra Treees Classsifier\netc_model = ExtraTreesClassifier(min_samples_leaf = 7, min_samples_split=2,\n                                  n_estimators = 100)\n# fit the model\netc_model.fit(X_train, y_train)\n\n#Predict Model\npredict_etc = etc_model.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Extreme Gradient Boosting\nxgb_model = XGBClassifier(criterion = 'giny', learning_rate = 0.01, max_depth = 5, n_estimators = 100,\n                          objective ='binary:logistic', subsample = 1.0)\n# fit the model\nxgb_model.fit(X_train, y_train)\n#Predict Model\npredict_xgb = xgb_model.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 6. Classification Reports and Classification Matrix"},{"metadata":{},"cell_type":"markdown","source":"The last part is comparison of classification reports of ML models. \n\nFirst comparison the accuracy results. Accuracy is a ratio of correct predictions to the the total predictions. According to that, *Random Forest* have the highest correctly prediction with 88%. \nAnother perfomance metrics explained below:\n\n* Precision: It explains when the predicted value is positive, what percentage was correct.\n* Recall: It explains when the actual value is positive, what percentage was classified correctly.\n* F1 Score: It explains the weighted average of the recall and precision.\n\nIn all performance metrics, *Random Forest* model have the highest percentage than other models. This model has a better prediction of actual cancel booking as cancel booking and predict least false canceled booking. As a result of all this numbers, *Random Forest* is the best-predicted algorithms in all models."},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"RF\", classification_report(y_test, predict_rf))\nprint(\"DTC\",classification_report(y_test, predict_dtc))\nprint(\"ETC\", classification_report(y_test, predict_etc))\nprint(\"XGB\", classification_report(y_test, predict_xgb))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"DTC_matrix = confusion_matrix(y_test, predict_dtc)\nRF_matrix = confusion_matrix(y_test, predict_rf)\nETC_matrix = confusion_matrix(y_test, predict_etc)\nXGB_matrix = confusion_matrix(y_test, predict_xgb) \n\nfig, ax = plt.subplots(1, 2, figsize=(15, 8))\nsns.heatmap(RF_matrix,annot=True, fmt=\"d\", cbar=False, cmap=\"Pastel2\",  ax = ax[0]).set_ylim([0,2])\nax[0].set_title(\"Random Forest\", weight='bold')\nax[0].set_xlabel('Predicted Labels')\nax[0].set_ylabel('Actual Labels')\nsns.heatmap(DTC_matrix,annot=True, fmt=\"d\" ,cbar=False, cmap=\"tab20\", ax = ax[1]).set_ylim([0,2])\nax[1].set_title(\"Decision Tree\", weight='bold')\nax[1].set_xlabel('Predicted Labels')\nax[1].set_ylabel('Actual Labels')\n\nfig, axe = plt.subplots(1, 2, figsize=(15, 8))\nsns.heatmap(ETC_matrix,annot=True, fmt=\"d\", cbar=False, cmap=\"Paired\", ax = axe[0]).set_ylim([0,2])\naxe[0].set_title(\"Extra Tree Classifier\", weight='bold')\naxe[0].set_xlabel('Predicted Labels')\naxe[0].set_ylabel('Actual Labels')\nsns.heatmap(XGB_matrix,annot=True, fmt=\"d\", cbar=False, cmap=\"Pastel1\", ax = axe[1]).set_ylim([0,2])\naxe[1].set_title(\"Gradient Boosting\", weight='bold')\naxe[1].set_xlabel('Predicted Labels')\naxe[1].set_ylabel('Actual Labels')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Any feedback is welcome, please be generous to share your feedbacks**"}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.4"}},"nbformat":4,"nbformat_minor":4}